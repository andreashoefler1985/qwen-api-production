# Produktions-Docker-Compose für ai.hoefler-cloud.com
# Gehärtete Konfiguration mit SSL und Nginx

services:
  nginx:
    image: nginx:1.25-alpine
    container_name: nginx-proxy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/app/ssl:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - qwen-api
    networks:
      - web
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    read_only: true
    tmpfs:
      - /var/cache/nginx:noexec,nosuid,size=100m
      - /var/run:noexec,nosuid,size=100m
      - /tmp:noexec,nosuid,size=50m
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  qwen-api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: qwen-api
    env_file:
      - .env.production
    user: "1000:1000"
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=500m
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    security_opt:
      - no-new-privileges:true
      - apparmor:unconfined
    expose:
      - "8000"
    volumes:
      - ./models:/app/models:ro
      - ./cache:/app/cache
      - ./logs:/app/logs
    environment:
      - JWT_SECRET=${JWT_SECRET}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - API_DOMAIN=ai.hoefler-cloud.com
      - ALLOWED_ORIGINS=https://ai.hoefler-cloud.com
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - CUDA_VISIBLE_DEVICES=0
      - ENVIRONMENT=production
      - MAX_REQUESTS_PER_HOUR=1000
      - MAX_CONCURRENT_REQUESTS=10
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 8G
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - web
      - backend
    healthcheck:
      test: ["CMD", "python3", "-c", "import requests; requests.get('http://localhost:8000/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  redis:
    image: redis:7.2-alpine
    container_name: redis-cache
    env_file:
      - .env.production
    user: "999:999"
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100m
    command: >
      redis-server 
      --requirepass ${REDIS_PASSWORD}
      --appendonly yes 
      --maxmemory 1gb 
      --maxmemory-policy allkeys-lru
      --bind 0.0.0.0
      --protected-mode yes
      --port 6379
      --tcp-keepalive 300
      --timeout 0
      --tcp-backlog 511
      --save 900 1
      --save 300 10
      --save 60 10000
    expose:
      - "6379"
    volumes:
      - redis_data:/data
    networks:
      - backend
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  fail2ban:
    image: crazymax/fail2ban:latest
    container_name: fail2ban-security
    restart: unless-stopped
    network_mode: "host"
    privileged: true
    cap_add:
      - NET_ADMIN
      - NET_RAW
    volumes:
      - ./fail2ban:/etc/fail2ban:ro
      - nginx_logs:/var/log/nginx:ro
      - /var/log:/var/log:ro
      - fail2ban_data:/data
    environment:
      - TZ=Europe/Berlin
      - F2B_LOG_LEVEL=INFO
      - F2B_DB_PURGE_AGE=1d
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  log-monitor:
    image: grafana/promtail:2.9.0
    container_name: log-monitor
    restart: unless-stopped
    volumes:
      - ./promtail-config.yml:/etc/promtail/config.yml:ro
      - nginx_logs:/var/log/nginx:ro
      - ./logs:/app/logs:ro
      - /var/log:/var/log:ro
    networks:
      - monitoring
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=50m

  backup:
    image: alpine:3.18
    container_name: backup-service
    env_file:
      - .env.production
    restart: "no"
    volumes:
      - ./models:/backup/models:ro
      - ./ssl:/backup/ssl:ro
      - ./logs:/backup/logs:ro
      - redis_data:/backup/redis:ro
      - ./backups:/backups
      - ./backup.sh:/backup.sh:ro
    environment:
      - BACKUP_RETENTION_DAYS=30
      - BACKUP_S3_BUCKET=${BACKUP_S3_BUCKET:-}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID:-}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY:-}
    command: /bin/sh -c "while true; do /backup.sh; sleep 86400; done"
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL

volumes:
  redis_data:
    driver: local
  nginx_logs:
    driver: local
  api_temp:
    driver: local
  fail2ban_data:
    driver: local

networks:
  web:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
  backend:
    driver: bridge
    internal: true
    ipam:
      config:
        - subnet: 172.21.0.0/16
  monitoring:
    driver: bridge
    internal: true
    ipam:
      config:
        - subnet: 172.22.0.0/16
